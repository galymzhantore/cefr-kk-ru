{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4847dd",
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = pathlib.Path.cwd()\n",
    "\n",
    "PROJECT_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import torch\n",
    "\n",
    "print(\"Python:\", platform.python_version())\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.download_parallel import save_kz_ru\n",
    "\n",
    "PARALLEL_PATH = save_kz_ru(split=\"train\", out_dir=\"data/parallel\", out_name=\"kazparc_kz_ru.csv\")\n",
    "PARALLEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.align.mutual_align import EmbeddingAligner\n",
    "from src.pipeline.build_silver_labels import main as build_silver_labels\n",
    "\n",
    "# Use GPU explicitly if available\n",
    "aligner_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "custom_aligner = EmbeddingAligner(device=aligner_device)\n",
    "\n",
    "SILVER_PATH = build_silver_labels(parallel_csv=PARALLEL_PATH, aligner=custom_aligner)\n",
    "SILVER_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "silver_df = pd.read_csv(SILVER_PATH)\n",
    "silver_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94247f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.text.predict_text import predict_text_cefr\n",
    "\n",
    "sample_row = silver_df.iloc[0]\n",
    "prediction = predict_text_cefr( # предсказать\n",
    "    sample_row['kaz_item'],\n",
    "    russian_text=sample_row['rus_item'],\n",
    ")\n",
    "prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a34d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from src.models.predict_transformer_word import load_model, WordRecord, compute_features, UNK_TOKEN, CEFR_LEVELS\n",
    "from src.utils import cefr_id_to_label  # only if you want the top class name\n",
    "\n",
    "word = \"легко\"\n",
    "model_path = Path(\"models/simple_word_cefr/simple_word_cefr.pt\")  # adjust if needed\n",
    "\n",
    "# Load model and cached stats\n",
    "artifact, model, device = load_model(model_path)\n",
    "char2idx = artifact[\"char2idx\"]\n",
    "feature_mean = np.array(artifact[\"feature_mean\"], dtype=np.float32)\n",
    "feature_std = np.array(artifact[\"feature_std\"], dtype=np.float32)\n",
    "total_frequency = float(artifact[\"total_frequency\"])\n",
    "\n",
    "# Feature + char encoding\n",
    "rec = WordRecord(word=word.lower(), label=0, frequency=1, rank_fraction=0.5)\n",
    "features = compute_features(rec, total_frequency)\n",
    "features = np.nan_to_num((features - feature_mean) / feature_std)\n",
    "\n",
    "char_ids = torch.tensor(\n",
    "    [char2idx.get(ch, char2idx[UNK_TOKEN]) for ch in rec.word], dtype=torch.long\n",
    ").unsqueeze(0)\n",
    "lengths = torch.tensor([char_ids.size(1)], dtype=torch.long)\n",
    "features_tensor = torch.tensor(features, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "char_ids = char_ids.to(device)\n",
    "lengths = lengths.to(device)\n",
    "features_tensor = features_tensor.to(device)\n",
    "\n",
    "# Forward pass\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(char_ids, lengths, features_tensor)\n",
    "    probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "\n",
    "# Display distribution\n",
    "distribution = dict(zip(CEFR_LEVELS, probs))\n",
    "print(f\"CEFR distribution for '{word}':\")\n",
    "for level, prob in distribution.items():\n",
    "    print(f\"  {level}: {prob:.4f}\")\n",
    "\n",
    "top_idx = int(np.argmax(probs))\n",
    "print(f\"\\nTop prediction: {CEFR_LEVELS[top_idx]} ({probs[top_idx]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b1c399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kazakh_cefr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
