{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b4847dd",
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/zhantore/Documents/cefr-kk-ru')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = pathlib.Path.cwd()\n",
    "\n",
    "PROJECT_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.19\n",
      "Torch: 2.7.1\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import torch\n",
    "\n",
    "print(\"Python:\", platform.python_version())\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 371902/371902 [00:02<00:00, 137309.00 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data/parallel/kazparc_kz_ru.csv rows: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('data/parallel/kazparc_kz_ru.csv')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data.download_parallel import save_kz_ru\n",
    "\n",
    "PARALLEL_PATH = save_kz_ru(split=\"train[:100]\", out_dir=\"data/parallel\", out_name=\"kazparc_kz_ru.csv\")\n",
    "PARALLEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at aneuraz/awesome-align-with-co and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data/labels/silver_word_labels.csv rows=928 skipped_sentences=0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('data/labels/silver_word_labels.csv')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.align.mutual_align import EmbeddingAligner\n",
    "from src.pipeline.build_silver_labels import main as build_silver_labels\n",
    "\n",
    "# Use GPU explicitly if available\n",
    "aligner_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "custom_aligner = EmbeddingAligner(device=aligner_device)\n",
    "\n",
    "SILVER_PATH = build_silver_labels(parallel_csv=PARALLEL_PATH, aligner=custom_aligner)\n",
    "SILVER_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kaz_item</th>\n",
       "      <th>rus_item</th>\n",
       "      <th>cefr</th>\n",
       "      <th>kaz_sent</th>\n",
       "      <th>rus_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>кезінде</td>\n",
       "      <td>При</td>\n",
       "      <td>B1</td>\n",
       "      <td>Қауіпті қалдықтар трансшекаралық тасымалдау ке...</td>\n",
       "      <td>При трансграничной перевозке опасные отходы до...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>трансшекаралық</td>\n",
       "      <td>трансграничной</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Қауіпті қалдықтар трансшекаралық тасымалдау ке...</td>\n",
       "      <td>При трансграничной перевозке опасные отходы до...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>тасымалдау</td>\n",
       "      <td>перевозке</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Қауіпті қалдықтар трансшекаралық тасымалдау ке...</td>\n",
       "      <td>При трансграничной перевозке опасные отходы до...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Қауіпті</td>\n",
       "      <td>опасные</td>\n",
       "      <td>B2</td>\n",
       "      <td>Қауіпті қалдықтар трансшекаралық тасымалдау ке...</td>\n",
       "      <td>При трансграничной перевозке опасные отходы до...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>қалдықтар</td>\n",
       "      <td>отходы</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Қауіпті қалдықтар трансшекаралық тасымалдау ке...</td>\n",
       "      <td>При трансграничной перевозке опасные отходы до...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>өте</td>\n",
       "      <td>Очень</td>\n",
       "      <td>A1</td>\n",
       "      <td>Суда жатқан өте үлкен әдемі піл.</td>\n",
       "      <td>Очень большой красивый слон, лежащий в воде.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>үлкен</td>\n",
       "      <td>большой</td>\n",
       "      <td>A1</td>\n",
       "      <td>Суда жатқан өте үлкен әдемі піл.</td>\n",
       "      <td>Очень большой красивый слон, лежащий в воде.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>әдемі</td>\n",
       "      <td>красивый</td>\n",
       "      <td>A2</td>\n",
       "      <td>Суда жатқан өте үлкен әдемі піл.</td>\n",
       "      <td>Очень большой красивый слон, лежащий в воде.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>піл.</td>\n",
       "      <td>слон,</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Суда жатқан өте үлкен әдемі піл.</td>\n",
       "      <td>Очень большой красивый слон, лежащий в воде.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>Суда</td>\n",
       "      <td>воде.</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Суда жатқан өте үлкен әдемі піл.</td>\n",
       "      <td>Очень большой красивый слон, лежащий в воде.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>928 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           kaz_item        rus_item     cefr  \\\n",
       "0           кезінде             При       B1   \n",
       "1    трансшекаралық  трансграничной  Unknown   \n",
       "2        тасымалдау       перевозке  Unknown   \n",
       "3           Қауіпті         опасные       B2   \n",
       "4         қалдықтар          отходы  Unknown   \n",
       "..              ...             ...      ...   \n",
       "923             өте           Очень       A1   \n",
       "924           үлкен         большой       A1   \n",
       "925           әдемі        красивый       A2   \n",
       "926            піл.           слон,  Unknown   \n",
       "927            Суда           воде.  Unknown   \n",
       "\n",
       "                                              kaz_sent  \\\n",
       "0    Қауіпті қалдықтар трансшекаралық тасымалдау ке...   \n",
       "1    Қауіпті қалдықтар трансшекаралық тасымалдау ке...   \n",
       "2    Қауіпті қалдықтар трансшекаралық тасымалдау ке...   \n",
       "3    Қауіпті қалдықтар трансшекаралық тасымалдау ке...   \n",
       "4    Қауіпті қалдықтар трансшекаралық тасымалдау ке...   \n",
       "..                                                 ...   \n",
       "923                   Суда жатқан өте үлкен әдемі піл.   \n",
       "924                   Суда жатқан өте үлкен әдемі піл.   \n",
       "925                   Суда жатқан өте үлкен әдемі піл.   \n",
       "926                   Суда жатқан өте үлкен әдемі піл.   \n",
       "927                   Суда жатқан өте үлкен әдемі піл.   \n",
       "\n",
       "                                              rus_sent  \n",
       "0    При трансграничной перевозке опасные отходы до...  \n",
       "1    При трансграничной перевозке опасные отходы до...  \n",
       "2    При трансграничной перевозке опасные отходы до...  \n",
       "3    При трансграничной перевозке опасные отходы до...  \n",
       "4    При трансграничной перевозке опасные отходы до...  \n",
       "..                                                 ...  \n",
       "923       Очень большой красивый слон, лежащий в воде.  \n",
       "924       Очень большой красивый слон, лежащий в воде.  \n",
       "925       Очень большой красивый слон, лежащий в воде.  \n",
       "926       Очень большой красивый слон, лежащий в воде.  \n",
       "927       Очень большой красивый слон, лежащий в воде.  \n",
       "\n",
       "[928 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "silver_df = pd.read_csv(SILVER_PATH)\n",
    "silver_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94247f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextCefrPrediction(translation='При', distribution={'A1': 0.0, 'A2': 0.0, 'B1': 1.0, 'B2': 0.0, 'C1': 0.0, 'C2': 0.0}, average_level='B1', phrase_alignments=[PhraseAlignment(kazakh_phrase='кезінде', russian_token='При', kazakh_span=(0,), russian_index=0)])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.text.predict_text import predict_text_cefr\n",
    "\n",
    "sample_row = silver_df.iloc[0]\n",
    "prediction = predict_text_cefr( # предсказать\n",
    "    sample_row['kaz_item'],\n",
    "    russian_text=sample_row['rus_item'],\n",
    ")\n",
    "prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5a34d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEFR distribution for 'легко':\n",
      "  A1: 0.4665\n",
      "  A2: 0.2356\n",
      "  B1: 0.1440\n",
      "  B2: 0.0671\n",
      "  C1: 0.0501\n",
      "  C2: 0.0367\n",
      "\n",
      "Top prediction: A1 (0.4665)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\nimport torch\nfrom pathlib import Path\n\nfrom src.models.predict_transformer_word import load_model, WordRecord, compute_features, UNK_TOKEN, CEFR_LEVELS\nfrom src.utils import cefr_id_to_label  # only if you want the top class name\n\nword = \"легко\"\nmodel_path = Path(\"models/simple_word_cefr/simple_word_cefr.pt\")  # adjust if needed\n\n# Load model and cached stats\nartifact, model, device = load_model(model_path)\nchar2idx = artifact[\"char2idx\"]\nfeature_mean = np.array(artifact[\"feature_mean\"], dtype=np.float32)\nfeature_std = np.array(artifact[\"feature_std\"], dtype=np.float32)\ntotal_frequency = float(artifact[\"total_frequency\"])\n\n# Feature + char encoding\nrec = WordRecord(word=word.lower(), label=0, frequency=1, rank_fraction=0.5)\nfeatures = compute_features(rec, total_frequency)\nfeatures = np.nan_to_num((features - feature_mean) / feature_std)\n\nchar_ids = torch.tensor(\n    [char2idx.get(ch, char2idx[UNK_TOKEN]) for ch in rec.word], dtype=torch.long\n).unsqueeze(0)\nlengths = torch.tensor([char_ids.size(1)], dtype=torch.long)\nfeatures_tensor = torch.tensor(features, dtype=torch.float32).unsqueeze(0)\n\nchar_ids = char_ids.to(device)\nlengths = lengths.to(device)\nfeatures_tensor = features_tensor.to(device)\n\n# Forward pass\nmodel.eval()\nwith torch.no_grad():\n    logits = model(char_ids, lengths, features_tensor)\n    probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n\n# Display distribution\ndistribution = dict(zip(CEFR_LEVELS, probs))\nprint(f\"CEFR distribution for '{word}':\")\nfor level, prob in distribution.items():\n    print(f\"  {level}: {prob:.4f}\")\n\ntop_idx = int(np.argmax(probs))\nprint(f\"\\nTop prediction: {CEFR_LEVELS[top_idx]} ({probs[top_idx]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b1c399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kazakh_cefr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}