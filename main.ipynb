{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kazakh → Russian CEFR Pipeline (Notebook)\n",
    "\n",
    "This notebook installs all dependencies, downloads a slice of the KazParC corpus, builds silver CEFR labels, and runs the text-level predictor. It works on CPU or GPU runtimes (e.g., Google Colab, Kaggle, or local) and only relies on internet access for model/data downloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b4847dd",
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/galymzhantore/Documents/cefr-kk-ru')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = pathlib.Path.cwd()\n",
    "\n",
    "PROJECT_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.18\n",
      "Torch: 2.5.1\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import torch\n",
    "\n",
    "print(\"Python:\", platform.python_version())\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download Kazakh–Russian parallel sentences\n",
    "\n",
    "We grab the first 10k sentence pairs for a quick demo. Set `split=\"train\"` for the full dataset once you’re ready for a longer run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data/parallel/kazparc_kz_ru.csv rows: 100\n"
     ]
    }
   ],
   "source": [
    "from src.data.download_parallel import save_kz_ru\n",
    "\n",
    "PARALLEL_PATH = save_kz_ru(split=\"train[:100]\", out_dir=\"data/parallel\", out_name=\"kazparc_kz_ru.csv\")\n",
    "PARALLEL_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build silver word-level CEFR labels\n",
    "\n",
    "Uses the mutual soft-aligner with fallback handling for very long sentences (those are skipped with a warning). Expect the first run to download the alignment model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m aligner_device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m custom_aligner \u001b[38;5;241m=\u001b[39m EmbeddingAligner(device\u001b[38;5;241m=\u001b[39maligner_device)\n\u001b[0;32m----> 8\u001b[0m SILVER_PATH \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_silver_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparallel_csv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPARALLEL_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maligner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_aligner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m SILVER_PATH\n",
      "File \u001b[0;32m~/Documents/cefr-kk-ru/src/pipeline/build_silver_labels.py:47\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(parallel_csv, rus_cefr, out_csv, aligner, layer, thresh)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m(\n\u001b[1;32m     40\u001b[0m     parallel_csv: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m Path \u001b[38;5;241m=\u001b[39m PARALLEL_CSV,\n\u001b[1;32m     41\u001b[0m     rus_cefr: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m Path \u001b[38;5;241m=\u001b[39m RUS_CEFR,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m     thresh: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m,\n\u001b[1;32m     46\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Path:\n\u001b[0;32m---> 47\u001b[0m     parallel_csv \u001b[38;5;241m=\u001b[39m \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparallel_csv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     rus_cefr \u001b[38;5;241m=\u001b[39m Path(rus_cefr)\n\u001b[1;32m     49\u001b[0m     out_csv \u001b[38;5;241m=\u001b[39m Path(out_csv)\n",
      "File \u001b[0;32m~/miniconda3/envs/kazakh_cefr_env/lib/python3.10/pathlib.py:960\u001b[0m, in \u001b[0;36mPath.__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m Path:\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m WindowsPath \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m PosixPath\n\u001b[0;32m--> 960\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_parts\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flavour\u001b[38;5;241m.\u001b[39mis_supported:\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot instantiate \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m on your system\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    963\u001b[0m                               \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,))\n",
      "File \u001b[0;32m~/miniconda3/envs/kazakh_cefr_env/lib/python3.10/pathlib.py:594\u001b[0m, in \u001b[0;36mPurePath._from_parts\u001b[0;34m(cls, args)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_from_parts\u001b[39m(\u001b[38;5;28mcls\u001b[39m, args):\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;66;03m# We need to call _parse_args on the instance, so as to get the\u001b[39;00m\n\u001b[1;32m    592\u001b[0m     \u001b[38;5;66;03m# right flavour.\u001b[39;00m\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m--> 594\u001b[0m     drv, root, parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drv \u001b[38;5;241m=\u001b[39m drv\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_root \u001b[38;5;241m=\u001b[39m root\n",
      "File \u001b[0;32m~/miniconda3/envs/kazakh_cefr_env/lib/python3.10/pathlib.py:578\u001b[0m, in \u001b[0;36mPurePath._parse_args\u001b[0;34m(cls, args)\u001b[0m\n\u001b[1;32m    576\u001b[0m     parts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39m_parts\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 578\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;66;03m# Force-cast str subclasses to str (issue #21127)\u001b[39;00m\n\u001b[1;32m    581\u001b[0m         parts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(a))\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "from src.align.mutual_align import EmbeddingAligner\n",
    "from src.pipeline.build_silver_labels import main as build_silver_labels\n",
    "\n",
    "# Use GPU explicitly if available\n",
    "aligner_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "custom_aligner = EmbeddingAligner(device=aligner_device)\n",
    "\n",
    "SILVER_PATH = build_silver_labels(parallel_csv=PARALLEL_PATH, aligner=custom_aligner)\n",
    "SILVER_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "silver_df = pd.read_csv(SILVER_PATH)\n",
    "silver_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run text-level CEFR prediction\n",
    "\n",
    "Translate a sample sentence, align phrases, and aggregate CEFR levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.domain.services import TextCefrPipeline, TranslationService, AlignmentService, CefrScorer\n",
    "from src.data.repositories import RussianCefrRepository\n",
    "from src.translation.translator import get_translator\n",
    "\n",
    "translator = get_translator(device=aligner_device)\n",
    "translation_service = TranslationService(translator)\n",
    "alignment_service = AlignmentService(custom_aligner)\n",
    "scorer = CefrScorer(RussianCefrRepository())\n",
    "\n",
    "pipeline = TextCefrPipeline(\n",
    "    translation_service=translation_service,\n",
    "    alignment_service=alignment_service,\n",
    "    scorer=scorer,\n",
    ")\n",
    "\n",
    "sample_text = \"Ол қыста ауылға барған еді\"\n",
    "prediction = pipeline.predict(sample_text)\n",
    "prediction.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"kazakh_phrase\": [p.kazakh_phrase for p in prediction.phrase_alignments],\n",
    "        \"russian_token\": [p.russian_token for p in prediction.phrase_alignments],\n",
    "        \"kazakh_span\": [p.kazakh_span for p in prediction.phrase_alignments],\n",
    "        \"russian_index\": [p.russian_index for p in prediction.phrase_alignments],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. (Optional) Train the word-level CEFR classifier\n",
    "\n",
    "Requires the silver labels generated above. Training on CPU is slow; GPU recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "optional"
    ]
   },
   "outputs": [],
   "source": [
    "# Uncomment to fine-tune the word-level classifier\n",
    "# !python -m src.models.train_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "- Increase the dataset slice to the full `train` split when you are ready for production data.\n",
    "- Persist outputs to cloud storage (e.g., Google Drive) if running in Colab.\n",
    "- Build a CLI or API on top of `TextCefrPipeline` for integration into larger systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kazakh_cefr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
